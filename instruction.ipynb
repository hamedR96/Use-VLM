{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb4df2a9-4d21-4b12-a407-7de0f79d72ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "# Step 6: Upload to Hugging Face\n",
    "# Login to Hugging Face Hub\n",
    "login(token='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')  # Replace with your Hugging Face token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b98bce5-b89e-4056-ba35-07caaa4e430d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU memory: 79.14 GB\n",
      "Memory allocated: 0.00 GB\n",
      "Memory reserved (cached): 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Check total memory available on the GPU\n",
    "    print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / (1024 ** 3):.2f} GB\")\n",
    "    \n",
    "    # Check memory allocated\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated() / (1024 ** 3):.2f} GB\")\n",
    "    \n",
    "    # Check memory cached (reserved)\n",
    "    print(f\"Memory reserved (cached): {torch.cuda.memory_reserved() / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"problem with GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964986a-cb27-4914-9aea-f00bd4246200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_id = \"google/paligemma2-10b-pt-896\" \n",
    "model_id = \"google/paligemma2-3b-pt-448\"\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05122377-6618-4a7f-aff7-e7e558241309",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.vision_tower.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.multi_modal_projector.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.language_model.parameters():\n",
    "    param.requires_grad = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a7f94f-d480-459b-acf2-0ed04c92f1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    dense_moe = True  \n",
    "    lora_rank = 128\n",
    "    lora_alpha = 256\n",
    "    num_experts = 5\n",
    "\n",
    "args = Args()\n",
    "\n",
    "for i in range(len(model.language_model.model.layers)):\n",
    "    original_mlp = model.language_model.model.layers[i].mlp\n",
    "    model.language_model.model.layers[i].mlp = LoRA_MOE_LM(args=args,\n",
    "                                                           lora_rank=args.lora_rank,\n",
    "                                                           lora_alpha=args.lora_alpha,\n",
    "                                                           num_experts=args.num_experts,\n",
    "                                                           original_module=original_mlp).bfloat16().to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df177d56-fddc-45aa-a5fb-2a586dd89d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_parameters(model):\n",
    "    # Calculate total and trainable parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # Calculate the percentage of trainable parameters\n",
    "    trainable_percentage = (trainable_params / total_params) * 100\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Percentage of trainable parameters: {trainable_percentage:.2f}%\")\n",
    "print_model_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99ebb80-2882-4980-9068-b59904331133",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_token = processor.tokenizer.convert_tokens_to_ids(\"<image>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4ad99-84e5-45de-8283-8acf4206a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "dataset=load_dataset(\"adlbh/alpagasus_train_fairuser_train_map_sft\")\n",
    "\n",
    "dt = dataset[\"train\"]\n",
    "dv = dataset[\"validation\"]\n",
    "dts=dataset[\"test\"]\n",
    "\n",
    "# Concatenate the two datasets\n",
    "dc = concatenate_datasets([dt, dv,dts])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
