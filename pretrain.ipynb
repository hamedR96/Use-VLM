{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b52e26b8-9c81-499e-bac9-e7ef74de2773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "# Step 6: Upload to Hugging Face\n",
    "# Login to Hugging Face Hub\n",
    "login(token='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')  # Replace with your Hugging Face token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc83072-4a9c-4764-8b99-c46b62e6f9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU memory: 79.14 GB\n",
      "Memory allocated: 0.00 GB\n",
      "Memory reserved (cached): 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    # Check total memory available on the GPU\n",
    "    print(f\"Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / (1024 ** 3):.2f} GB\")\n",
    "    \n",
    "    # Check memory allocated\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated() / (1024 ** 3):.2f} GB\")\n",
    "    \n",
    "    # Check memory cached (reserved)\n",
    "    print(f\"Memory reserved (cached): {torch.cuda.memory_reserved() / (1024 ** 3):.2f} GB\")\n",
    "else:\n",
    "    print(\"problem with GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9037cf08-a189-444d-8017-615b0fdbc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "from transformers import PaliGemmaProcessor, PaliGemmaForConditionalGeneration, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "\n",
    "dataset=load_dataset(\"hamedrahimi/FairUser\")\n",
    "\n",
    "dt = dataset[\"train\"]\n",
    "dv = dataset[\"validation\"]\n",
    "dts=dataset[\"test\"]\n",
    "\n",
    "# Concatenate the two datasets\n",
    "dc = concatenate_datasets([dt, dv,dts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753ca27c-8633-42a4-9d19-ef785f498b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb12797769a44d35ae9270b0ff8afaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model_id = \"google/paligemma2-10b-pt-896\" \n",
    "model_id = \"google/paligemma2-3b-pt-448\"\n",
    "processor = PaliGemmaProcessor.from_pretrained(model_id)\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.bfloat16).to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "image_token = processor.tokenizer.convert_tokens_to_ids(\"<image>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04049aca-856f-48e8-93c1-dbea7f46b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Pretraining\n",
    "def collate_fn(examples):\n",
    "  texts = [\"<image>user profile: \" for example in examples]\n",
    "  labels= [example['user_profile'] for example in examples]\n",
    "  images = [example[\"image\"].convert(\"RGB\") for example in examples]\n",
    "  tokens = processor(text=texts, images=images, suffix=labels,\n",
    "                    return_tensors=\"pt\", padding=\"longest\")\n",
    "  tokens = tokens.to(model.dtype).to(device)\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03bf2ae6-7bcf-4547-a8f8-1e9f62b1e0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.vision_tower.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#for param in model.multi_modal_projector.parameters():\n",
    "    #param.requires_grad = False\n",
    "    \n",
    "for param in model.language_model.parameters():\n",
    "    param.requires_grad = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "967cd291-4674-4995-a711-0d15de5b4b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 3,033,127,152\n",
      "Trainable parameters: 2,656,512\n",
      "Percentage of trainable parameters: 0.09%\n"
     ]
    }
   ],
   "source": [
    "def print_model_parameters(model):\n",
    "    # Calculate total and trainable parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # Calculate the percentage of trainable parameters\n",
    "    trainable_percentage = (trainable_params / total_params) * 100\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "    print(f\"Percentage of trainable parameters: {trainable_percentage:.2f}%\")\n",
    "print_model_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51269fed-777d-4d4e-a4b7-d18ddad6f63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahimi/.local/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits,image_hidden_states. For reference, the inputs it received are input_ids,attention_mask,pixel_values.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m\n\u001b[1;32m      1\u001b[0m args\u001b[38;5;241m=\u001b[39mTrainingArguments(\n\u001b[1;32m      2\u001b[0m             num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      3\u001b[0m             remove_unused_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m             dataloader_pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         )\n\u001b[1;32m     23\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     24\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     25\u001b[0m         train_dataset\u001b[38;5;241m=\u001b[39mdc ,\n\u001b[1;32m     26\u001b[0m         data_collator\u001b[38;5;241m=\u001b[39mcollate_fn,\n\u001b[1;32m     27\u001b[0m         args\u001b[38;5;241m=\u001b[39margs\n\u001b[1;32m     28\u001b[0m         )\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2155\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2153\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   2154\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 2155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2156\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2160\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2162\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2522\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2516\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2517\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2519\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2520\u001b[0m )\n\u001b[1;32m   2521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2522\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2525\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2528\u001b[0m ):\n\u001b[1;32m   2529\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:3652\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3652\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3654\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3658\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:3727\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[0;32m-> 3727\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3728\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3729\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3730\u001b[0m         )\n\u001b[1;32m   3731\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[1;32m   3732\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits,image_hidden_states. For reference, the inputs it received are input_ids,attention_mask,pixel_values."
     ]
    }
   ],
   "source": [
    "args=TrainingArguments(\n",
    "            num_train_epochs=1,\n",
    "            remove_unused_columns=False,\n",
    "            per_device_train_batch_size=8,\n",
    "            gradient_accumulation_steps=8,\n",
    "            warmup_steps=2,\n",
    "            learning_rate=2e-5,\n",
    "            weight_decay=1e-6,\n",
    "            adam_beta2=0.999,\n",
    "            logging_steps=100,\n",
    "            optim=\"adamw_hf\",\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=1000,\n",
    "            save_total_limit=1,\n",
    "            push_to_hub=True,\n",
    "            output_dir=\"Profiler-3b\",\n",
    "            bf16=True,\n",
    "            report_to=[\"tensorboard\"],\n",
    "            dataloader_pin_memory=False\n",
    "        )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        train_dataset=dc ,\n",
    "        data_collator=collate_fn,\n",
    "        args=args\n",
    "        )\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ca4ffe-7781-4510-ad08-49da9e784c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd5156c-afd4-4c8b-beba-a2ccc537b313",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
